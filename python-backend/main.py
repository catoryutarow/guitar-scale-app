"""
éŸ³æºè§£æãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ API (FastAPI)

Phase 3 å®Ÿè£…å†…å®¹ï¼š
- POST /analyze ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ€ãƒŸãƒ¼è§£æãƒ­ã‚¸ãƒƒã‚¯ï¼‰
- Next.js ã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘ä»˜ã‘
- ãƒ€ãƒŸãƒ¼ã®è§£æçµæœã‚’è¿”å´

Phase 4 ä»¥é™ã§å®Ÿè£…äºˆå®šï¼š
- å®Ÿéš›ã®stemåˆ†è§£ï¼ˆDemucsï¼‰
- ã‚³ãƒ¼ãƒ‰è§£æï¼ˆlibrosa / madmomï¼‰
- ãƒ†ãƒ³ãƒãƒ»ã‚­ãƒ¼æ¤œå‡º
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
import os
from pathlib import Path
from dotenv import load_dotenv
import requests
import tempfile

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ============================================
# FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# ============================================

app = FastAPI(
    title="Audio Analysis API",
    description="éŸ³æºè§£æãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API - ã‚³ãƒ¼ãƒ‰é€²è¡Œãƒ»stemåˆ†è§£ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«æ¤œå‡º",
    version="0.1.0 (Phase 3 - Dummy)"
)

# CORSè¨­å®šï¼ˆNext.js ã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # Next.js é–‹ç™ºã‚µãƒ¼ãƒãƒ¼
        "http://127.0.0.1:3000",
        "https://*.vercel.app",  # Vercel ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
        "*",  # æœ¬ç•ªç’°å¢ƒç”¨ï¼ˆä¸€æ™‚çš„ã«å…¨è¨±å¯ã€å¾Œã§åˆ¶é™ï¼‰
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================
# Pydantic ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆTypeScript å‹ã¨å¯¾å¿œï¼‰
# ============================================

class AnalysisOptions(BaseModel):
    """è§£æã‚ªãƒ—ã‚·ãƒ§ãƒ³"""
    separateStems: bool = True
    analysisDepth: str = "basic"  # "basic" | "detailed"


class AnalyzeRequest(BaseModel):
    """è§£æãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    jobId: str = Field(..., description="ã‚¸ãƒ§ãƒ–ID")
    filePath: str = Field(..., description="éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    options: Optional[AnalysisOptions] = None


class AnalysisMetadata(BaseModel):
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
    duration: float
    tempo: float
    timeSignature: str
    detectedKey: str
    scale: str
    confidence: float


class ChordInfo(BaseModel):
    """ã‚³ãƒ¼ãƒ‰æƒ…å ±"""
    startTime: float
    endTime: float
    chord: str
    rootNote: str
    quality: str
    confidence: float


class ScaleMatchInfo(BaseModel):
    """ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒƒãƒãƒ³ã‚°æƒ…å ±"""
    scale: str
    rootNote: str
    matchRate: float
    matchingChords: List[str]


class ScaleMatchResult(BaseModel):
    """ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒƒãƒãƒ³ã‚°çµæœ"""
    matchingScales: List[ScaleMatchInfo]


class AnalysisResult(BaseModel):
    """è§£æçµæœ"""
    metadata: AnalysisMetadata
    chordProgression: List[ChordInfo]
    scaleMatch: ScaleMatchResult
    stems: Optional[Dict[str, str]] = None


class AnalyzeResponse(BaseModel):
    """è§£æãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    success: bool
    jobId: str
    status: str  # "completed" | "failed"
    result: Optional[AnalysisResult] = None
    error: Optional[str] = None


# ============================================
# ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è§£æãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ
# ============================================

USE_REAL_ANALYSIS = os.getenv("USE_REAL_ANALYSIS", "false").lower() == "true"

print("=" * 60)
print("ğŸµ Audio Analysis API - Startup")
print("=" * 60)
print(f"Analysis Mode: {'REAL (librosa)' if USE_REAL_ANALYSIS else 'DUMMY (å›ºå®šå€¤)'}")
print(f"Environment: USE_REAL_ANALYSIS={os.getenv('USE_REAL_ANALYSIS', 'not set')}")

# librosaã¯å®Ÿè§£æãƒ¢ãƒ¼ãƒ‰ã§ã®ã¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆä¾å­˜é–¢ä¿‚ã‚’æ¸›ã‚‰ã™ãŸã‚ï¼‰
if USE_REAL_ANALYSIS:
    try:
        import librosa
        import numpy as np
        print("âœ“ librosa loaded successfully")
        print("âœ“ numpy loaded successfully")
        print("=" * 60)
    except ImportError as e:
        print(f"âš  Warning: librosa not available - {e}")
        print("  Falling back to DUMMY analysis mode")
        print("=" * 60)
        USE_REAL_ANALYSIS = False
else:
    print("â„¹ Using DUMMY mode (set USE_REAL_ANALYSIS=true for real analysis)")
    print("=" * 60)

# ============================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ============================================

def download_file_if_url(file_path: str) -> str:
    """
    URLã®å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã€
    ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™

    Args:
        file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯URL

    Returns:
        str: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    # URLã‹ã©ã†ã‹ã‚’åˆ¤å®š
    if file_path.startswith('http://') or file_path.startswith('https://'):
        print(f"  â†’ Downloading file from URL: {file_path}")

        try:
            # URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            response = requests.get(file_path, timeout=30)
            response.raise_for_status()

            # æ‹¡å¼µå­ã‚’å–å¾—ï¼ˆURLã‹ã‚‰ï¼‰
            ext = '.mp3'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            if '.' in file_path:
                ext = '.' + file_path.split('.')[-1].split('?')[0]  # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤å»

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp_file:
                tmp_file.write(response.content)
                local_path = tmp_file.name

            print(f"  â†’ Downloaded to: {local_path} ({len(response.content)} bytes)")
            return local_path

        except requests.RequestException as e:
            raise HTTPException(
                status_code=400,
                detail=f"Failed to download file from URL: {str(e)}"
            )
    else:
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        print(f"  â†’ Using local file: {file_path}")
        return file_path


# ============================================
# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ============================================

@app.get("/")
def read_root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "ok",
        "message": "Audio Analysis API is running",
        "version": "0.1.0 (Phase 3 - Dummy)",
        "endpoints": [
            {"path": "/analyze", "method": "POST", "description": "éŸ³æºè§£æ"}
        ]
    }


@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_audio(request: AnalyzeRequest):
    """
    éŸ³æºè§£æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Phase 3 å®Ÿè£…ï¼š
    - ãƒ€ãƒŸãƒ¼ã®è§£æçµæœã‚’è¿”å´
    - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèªã®ã¿å®Ÿæ–½

    Phase 4 ä»¥é™ï¼š
    - å®Ÿéš›ã®éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    - Demucs ã§ stem åˆ†è§£
    - librosa / madmom ã§ã‚³ãƒ¼ãƒ‰è§£æ
    - ãƒ†ãƒ³ãƒãƒ»ã‚­ãƒ¼æ¤œå‡º
    """

    try:
        print("\n" + "=" * 60)
        print(f"ğŸµ Analyzing audio file")
        print("=" * 60)
        print(f"Job ID: {request.jobId}")
        print(f"File Path/URL: {request.filePath}")
        print(f"Options: {request.options}")
        print(f"Analysis Mode: {'REAL (librosa)' if USE_REAL_ANALYSIS else 'DUMMY (å›ºå®šå€¤)'}")
        print("=" * 60)

        # URLã®å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
        local_file_path = download_file_if_url(request.filePath)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        file_path = Path(local_file_path)

        if not file_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"Audio file not found: {local_file_path}"
            )

        # ç’°å¢ƒå¤‰æ•°ã«å¿œã˜ã¦å®Ÿè§£æ or ãƒ€ãƒŸãƒ¼è§£æã‚’é¸æŠ
        if USE_REAL_ANALYSIS:
            print("â†’ Calling analyze_audio_real()...")
            result = analyze_audio_real(
                file_path=local_file_path,
                options=request.options.dict() if request.options else {}
            )
        else:
            print("â†’ Calling analyze_audio_dummy()...")
            result = analyze_audio_dummy(
                file_path=local_file_path,
                options=request.options.dict() if request.options else {}
            )

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”å´
        print(f"\nâœ“ Analysis completed for job {request.jobId}")
        print("=" * 60 + "\n")

        return AnalyzeResponse(
            success=True,
            jobId=request.jobId,
            status="completed",
            result=result
        )

    except FileNotFoundError as e:
        print(f"\nâœ— File not found error: {str(e)}")
        print("=" * 60 + "\n")
        raise HTTPException(status_code=404, detail=str(e))

    except Exception as e:
        print(f"\nâœ— Analysis error: {str(e)}")
        import traceback
        traceback.print_exc()
        print("=" * 60 + "\n")
        raise HTTPException(
            status_code=500,
            detail=f"Analysis failed: {str(e)}"
        )
# ============================================
# ãƒ€ãƒŸãƒ¼è§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆPhase 3 å®Ÿè£…ï¼‰
# ============================================

def analyze_audio_dummy(file_path: str, options: Dict) -> AnalysisResult:
    """
    ãƒ€ãƒŸãƒ¼è§£æãƒ­ã‚¸ãƒƒã‚¯

    Phase 3: å›ºå®šã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    Phase 4: ã“ã“ã‚’å®Ÿéš›ã®è§£æãƒ­ã‚¸ãƒƒã‚¯ã«å·®ã—æ›¿ãˆã‚‹

    Args:
        file_path: éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        options: è§£æã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        AnalysisResult: è§£æçµæœ
    """

    print(f"\n[Dummy Analysis] Returning fixed dummy data...")
    print(f"  File: {file_path} (not actually analyzed)")
    print(f"  Result: G ãƒ¡ã‚¸ãƒ£ãƒ¼, 120.0 BPM, 8 chords (å›ºå®šå€¤)")
    print("=" * 60)

    # TODO (Phase 4): å®Ÿéš›ã®éŸ³æºè§£æå‡¦ç†ã«å·®ã—æ›¿ãˆ
    # 1. librosa ã§éŸ³æºã‚’èª­ã¿è¾¼ã¿
    # y, sr = librosa.load(file_path)
    #
    # 2. ãƒ†ãƒ³ãƒæ¤œå‡º
    # tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    #
    # 3. ã‚­ãƒ¼æ¤œå‡º
    # chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    # key = estimate_key(chroma)
    #
    # 4. ã‚³ãƒ¼ãƒ‰é€²è¡Œæ¤œå‡º
    # chords = detect_chords(y, sr)
    #
    # 5. stem åˆ†è§£ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # if options.get('separateStems'):
    #     stems = separate_stems(file_path)

    # Phase 3: ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    metadata = AnalysisMetadata(
        duration=120.0,
        tempo=120.0,
        timeSignature="4/4",
        detectedKey="G",
        scale="ãƒ¡ã‚¸ãƒ£ãƒ¼",
        confidence=0.95
    )

    chord_progression = [
        ChordInfo(
            startTime=0.0, endTime=4.0,
            chord="G", rootNote="G", quality="maj", confidence=0.9
        ),
        ChordInfo(
            startTime=4.0, endTime=8.0,
            chord="Em", rootNote="E", quality="min", confidence=0.88
        ),
        ChordInfo(
            startTime=8.0, endTime=12.0,
            chord="C", rootNote="C", quality="maj", confidence=0.87
        ),
        ChordInfo(
            startTime=12.0, endTime=16.0,
            chord="D", rootNote="D", quality="maj", confidence=0.9
        ),
        ChordInfo(
            startTime=16.0, endTime=20.0,
            chord="G", rootNote="G", quality="maj", confidence=0.92
        ),
        ChordInfo(
            startTime=20.0, endTime=24.0,
            chord="Em", rootNote="E", quality="min", confidence=0.85
        ),
        ChordInfo(
            startTime=24.0, endTime=28.0,
            chord="Am", rootNote="A", quality="min", confidence=0.89
        ),
        ChordInfo(
            startTime=28.0, endTime=32.0,
            chord="D", rootNote="D", quality="maj", confidence=0.91
        ),
    ]

    scale_match = ScaleMatchResult(
        matchingScales=[
            ScaleMatchInfo(
                scale="ãƒ¡ã‚¸ãƒ£ãƒ¼",
                rootNote="G",
                matchRate=0.95,
                matchingChords=["G", "C", "D", "Em", "Am"]
            ),
            ScaleMatchInfo(
                scale="ãƒã‚¤ãƒŠãƒ¼",
                rootNote="E",
                matchRate=0.88,
                matchingChords=["Em", "G", "C", "D", "Am"]
            ),
            ScaleMatchInfo(
                scale="ãƒŸã‚¯ã‚½ãƒªãƒ‡ã‚£ã‚¢ãƒ³",
                rootNote="G",
                matchRate=0.82,
                matchingChords=["G", "C", "D", "Em"]
            ),
        ]
    )

    return AnalysisResult(
        metadata=metadata,
        chordProgression=chord_progression,
        scaleMatch=scale_match,
        stems=None  # Phase 4 ã§ stem åˆ†è§£çµæœã‚’è¿”ã™
    )


# ============================================
# å®Ÿè§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆPhase 4 - librosa ãƒ™ãƒ¼ã‚¹ï¼‰
# ============================================

def analyze_audio_real(file_path: str, options: Dict) -> AnalysisResult:
    """
    å®Ÿéš›ã®éŸ³æºè§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆlibrosa ãƒ™ãƒ¼ã‚¹ï¼‰

    Phase 4 å®Ÿè£…å†…å®¹ï¼š
    - librosa ã§éŸ³æºã‚’èª­ã¿è¾¼ã¿ï¼ˆå…ˆé ­60ç§’ã«åˆ¶é™ï¼‰
    - ãƒ†ãƒ³ãƒæ¤œå‡º
    - ã‚­ãƒ¼/ã‚¹ã‚±ãƒ¼ãƒ«æ¨å®šï¼ˆç°¡æ˜“ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
    - ç°¡æ˜“ã‚³ãƒ¼ãƒ‰é€²è¡Œæ¤œå‡ºï¼ˆ4ç§’ã”ã¨ã®åŒºé–“åˆ†å‰²ï¼‰

    Args:
        file_path: éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        options: è§£æã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        AnalysisResult: è§£æçµæœ
    """

    print(f"\n[Real Analysis] Starting analysis...")
    print(f"  File: {file_path}")

    # 1. éŸ³å£°èª­ã¿è¾¼ã¿ï¼ˆå…ˆé ­60ç§’ã«åˆ¶é™ã—ã¦è² è·è»½æ¸›ï¼‰
    try:
        print(f"  Step 1/5: Loading audio file...")
        y, sr = librosa.load(file_path, sr=None, mono=True, duration=60.0)
        duration = len(y) / sr
        print(f"    âœ“ Loaded: {duration:.2f}s, sr={sr}Hz, samples={len(y)}")
    except Exception as e:
        print(f"    âœ— Failed to load audio file: {str(e)}")
        raise Exception(f"Failed to load audio file: {str(e)}")

    # 2. ãƒ†ãƒ³ãƒæ¨å®š
    try:
        print(f"  Step 2/5: Detecting tempo...")
        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
        tempo = float(tempo)
        print(f"    âœ“ Tempo detected: {tempo:.1f} BPM")
    except Exception as e:
        print(f"    âš  Tempo detection failed: {e}, using default 120 BPM")
        tempo = 120.0

    # 3. ã‚­ãƒ¼/ã‚¹ã‚±ãƒ¼ãƒ«æ¨å®šï¼ˆç°¡æ˜“ï¼‰
    try:
        print(f"  Step 3/5: Estimating key and scale...")
        detected_key, scale_name, confidence = estimate_key_simple(y, sr)
        print(f"    âœ“ Key detected: {detected_key} {scale_name} (confidence: {confidence:.2f})")
    except Exception as e:
        print(f"    âš  Key detection failed: {e}, using default G major")
        detected_key = "G"
        scale_name = "ãƒ¡ã‚¸ãƒ£ãƒ¼"
        confidence = 0.5

    # 4. ç°¡æ˜“ã‚³ãƒ¼ãƒ‰é€²è¡Œæ¤œå‡º
    try:
        print(f"  Step 4/5: Detecting chord progression...")
        chord_progression = detect_chords_simple(y, sr, detected_key, scale_name)
        print(f"    âœ“ Detected {len(chord_progression)} chord segments")
        if len(chord_progression) > 0:
            print(f"    First chord: {chord_progression[0].chord} ({chord_progression[0].startTime:.1f}s - {chord_progression[0].endTime:.1f}s)")
    except Exception as e:
        print(f"    âš  Chord detection failed: {e}, using fallback")
        chord_progression = generate_fallback_chords(detected_key, duration)

    # 5. ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒƒãƒãƒ³ã‚°
    try:
        print(f"  Step 5/5: Generating scale matches...")
        scale_match = generate_scale_match(detected_key, scale_name, chord_progression)
        print(f"    âœ“ Generated {len(scale_match.matchingScales)} scale matches")
        if len(scale_match.matchingScales) > 0:
            top_match = scale_match.matchingScales[0]
            print(f"    Top match: {top_match.rootNote} {top_match.scale} (match rate: {top_match.matchRate:.2%})")
    except Exception as e:
        print(f"    âš  Scale matching failed: {e}")
        scale_match = ScaleMatchResult(matchingScales=[])

    # 6. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
    metadata = AnalysisMetadata(
        duration=duration,
        tempo=tempo,
        timeSignature="4/4",  # å›ºå®š
        detectedKey=detected_key,
        scale=scale_name,
        confidence=confidence
    )

    print(f"\n[Real Analysis] Analysis completed successfully!")
    print(f"  Result: {detected_key} {scale_name}, {tempo:.1f} BPM, {len(chord_progression)} chords")
    print("=" * 60)

    return AnalysisResult(
        metadata=metadata,
        chordProgression=chord_progression,
        scaleMatch=scale_match,
        stems=None  # Phase 4 ã§ã¯æœªå®Ÿè£…
    )


def estimate_key_simple(y, sr):
    """
    ç°¡æ˜“ã‚­ãƒ¼æ¨å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

    chromaãƒ™ãƒ¼ã‚¹ã®12æ¬¡å…ƒãƒ”ãƒƒãƒã‚¯ãƒ©ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã€
    ãƒ¡ã‚¸ãƒ£ãƒ¼/ãƒã‚¤ãƒŠãƒ¼ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ç›¸é–¢ã‚’å–ã£ã¦æ¨å®šã™ã‚‹ã€‚

    Returns:
        Tuple[str, str, float]: (rootNote, scale, confidence)
    """

    # chromaç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆã‚¯ãƒ­ãƒã‚°ãƒ©ãƒ ï¼‰
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)

    # æ™‚é–“è»¸ã§å¹³å‡åŒ–ã—ã¦12æ¬¡å…ƒã®ãƒ”ãƒƒãƒã‚¯ãƒ©ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«
    chroma_mean = np.mean(chroma, axis=1)

    # æ­£è¦åŒ–
    chroma_mean = chroma_mean / (np.sum(chroma_mean) + 1e-8)

    # ãƒ¡ã‚¸ãƒ£ãƒ¼/ãƒã‚¤ãƒŠãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆKrumhansl-Kessler profilesï¼‰
    # ãƒ¡ã‚¸ãƒ£ãƒ¼: ãƒ‰(1.0), ãƒ¬(0.3), ãƒŸ(0.8), ãƒ•ã‚¡(0.4), ã‚½(0.9), ãƒ©(0.5), ã‚·(0.7)
    major_template = np.array([1.0, 0.2, 0.3, 0.2, 0.8, 0.4, 0.2, 0.9, 0.3, 0.5, 0.3, 0.7])

    # ãƒã‚¤ãƒŠãƒ¼: ãƒ©(1.0), ã‚·(0.3), ãƒ‰(0.8), ãƒ¬(0.4), ãƒŸ(0.9), ãƒ•ã‚¡(0.5), ã‚½(0.7)
    # ï¼ˆAãƒã‚¤ãƒŠãƒ¼ãƒ™ãƒ¼ã‚¹ â†’ 0ã‹ã‚‰å§‹ã¾ã‚‹ã‚ˆã†ã«9ã¤ã‚·ãƒ•ãƒˆï¼‰
    minor_template = np.array([1.0, 0.2, 0.8, 0.3, 0.4, 0.9, 0.2, 0.5, 0.2, 0.7, 0.3, 0.3])

    # æ­£è¦åŒ–
    major_template = major_template / np.sum(major_template)
    minor_template = minor_template / np.sum(minor_template)

    # 12éŸ³ã™ã¹ã¦ã®å¯èƒ½æ€§ã‚’è©¦ã™ï¼ˆç›¸é–¢ä¿‚æ•°ã§è©•ä¾¡ï¼‰
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']

    best_score = -1.0
    best_key = 'C'
    best_scale = 'ãƒ¡ã‚¸ãƒ£ãƒ¼'

    for i in range(12):
        # ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’iåŠéŸ³åˆ†ã‚·ãƒ•ãƒˆ
        shifted_major = np.roll(major_template, i)
        major_corr = np.corrcoef(chroma_mean, shifted_major)[0, 1]

        if major_corr > best_score:
            best_score = major_corr
            best_key = note_names[i]
            best_scale = 'ãƒ¡ã‚¸ãƒ£ãƒ¼'

        # ãƒã‚¤ãƒŠãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’iåŠéŸ³åˆ†ã‚·ãƒ•ãƒˆ
        shifted_minor = np.roll(minor_template, i)
        minor_corr = np.corrcoef(chroma_mean, shifted_minor)[0, 1]

        if minor_corr > best_score:
            best_score = minor_corr
            best_key = note_names[i]
            best_scale = 'ãƒã‚¤ãƒŠãƒ¼'

    # ä¿¡é ¼åº¦ã‚’0-1ã«æ­£è¦åŒ–ï¼ˆç›¸é–¢ä¿‚æ•°ã¯-1ã€œ1ãªã®ã§ã€0.5ã€œ1.0ã«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
    confidence = (best_score + 1.0) / 2.0
    confidence = max(0.0, min(1.0, confidence))

    return best_key, best_scale, confidence


def detect_chords_simple(y, sr, key_root, key_scale):
    """
    ç°¡æ˜“ã‚³ãƒ¼ãƒ‰é€²è¡Œæ¤œå‡º

    æ›²ã‚’4ç§’ã”ã¨ã®åŒºé–“ã«åˆ†å‰²ã—ã€å„åŒºé–“ã®chromaã‹ã‚‰
    ãã®ã‚­ãƒ¼ã®ãƒ€ã‚¤ã‚¢ãƒˆãƒ‹ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰ã®ã©ã‚Œã«è¿‘ã„ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚

    Returns:
        List[ChordInfo]: ã‚³ãƒ¼ãƒ‰é€²è¡Œ
    """

    duration = len(y) / sr
    segment_duration = 4.0  # 4ç§’ã”ã¨
    num_segments = int(np.ceil(duration / segment_duration))

    # ãƒ€ã‚¤ã‚¢ãƒˆãƒ‹ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰ã®å®šç¾©ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    # ãƒ¡ã‚¸ãƒ£ãƒ¼ã‚­ãƒ¼ã®å ´åˆ: I, ii, iii, IV, V, vi, viiÂ°
    # ãƒã‚¤ãƒŠãƒ¼ã‚­ãƒ¼ã®å ´åˆ: i, iiÂ°, III, iv, v, VI, VII

    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    root_index = note_names.index(key_root)

    if key_scale == 'ãƒ¡ã‚¸ãƒ£ãƒ¼':
        # I, IV, V (maj), ii, iii, vi (min)
        diatonic_chords = [
            {'offset': 0, 'quality': 'maj', 'degree': 'I'},    # I (ãƒˆãƒ‹ãƒƒã‚¯)
            {'offset': 2, 'quality': 'min', 'degree': 'ii'},   # ii
            {'offset': 4, 'quality': 'min', 'degree': 'iii'},  # iii
            {'offset': 5, 'quality': 'maj', 'degree': 'IV'},   # IV (ã‚µãƒ–ãƒ‰ãƒŸãƒŠãƒ³ãƒˆ)
            {'offset': 7, 'quality': 'maj', 'degree': 'V'},    # V (ãƒ‰ãƒŸãƒŠãƒ³ãƒˆ)
            {'offset': 9, 'quality': 'min', 'degree': 'vi'},   # vi (ç›¸å¯¾ãƒã‚¤ãƒŠãƒ¼)
        ]
    else:  # ãƒã‚¤ãƒŠãƒ¼
        # i, iv, v (min), III, VI, VII (maj)
        diatonic_chords = [
            {'offset': 0, 'quality': 'min', 'degree': 'i'},    # i (ãƒˆãƒ‹ãƒƒã‚¯)
            {'offset': 3, 'quality': 'maj', 'degree': 'III'},  # III
            {'offset': 5, 'quality': 'min', 'degree': 'iv'},   # iv
            {'offset': 7, 'quality': 'min', 'degree': 'v'},    # v
            {'offset': 8, 'quality': 'maj', 'degree': 'VI'},   # VI
            {'offset': 10, 'quality': 'maj', 'degree': 'VII'}, # VII
        ]

    chord_progression = []

    for seg_idx in range(num_segments):
        start_time = seg_idx * segment_duration
        end_time = min((seg_idx + 1) * segment_duration, duration)

        # ã“ã®åŒºé–“ã®éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)
        y_segment = y[start_sample:end_sample]

        if len(y_segment) < sr * 0.5:  # 0.5ç§’æœªæº€ãªã‚‰ç„¡è¦–
            continue

        # chromaç‰¹å¾´é‡ã‚’è¨ˆç®—
        chroma_seg = librosa.feature.chroma_stft(y=y_segment, sr=sr)
        chroma_mean = np.mean(chroma_seg, axis=1)

        # å„ãƒ€ã‚¤ã‚¢ãƒˆãƒ‹ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰ã¨ã®ä¸€è‡´åº¦ã‚’è¨ˆç®—
        best_match_score = -1.0
        best_chord = diatonic_chords[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒˆãƒ‹ãƒƒã‚¯

        for chord_info in diatonic_chords:
            chord_root_index = (root_index + chord_info['offset']) % 12

            # ã‚³ãƒ¼ãƒ‰ã®ãƒ«ãƒ¼ãƒˆéŸ³ã€ç¬¬3éŸ³ã€ç¬¬5éŸ³ã‚’å¼·èª¿ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            chord_template = np.zeros(12)
            chord_template[chord_root_index] = 1.0  # ãƒ«ãƒ¼ãƒˆ

            if chord_info['quality'] == 'maj':
                chord_template[(chord_root_index + 4) % 12] = 0.8  # é•·3åº¦
            else:  # min
                chord_template[(chord_root_index + 3) % 12] = 0.8  # çŸ­3åº¦

            chord_template[(chord_root_index + 7) % 12] = 0.6  # å®Œå…¨5åº¦

            # æ­£è¦åŒ–
            chord_template = chord_template / (np.sum(chord_template) + 1e-8)
            chroma_mean_norm = chroma_mean / (np.sum(chroma_mean) + 1e-8)

            # å†…ç©ã§ä¸€è‡´åº¦ã‚’è¨ˆç®—
            match_score = np.dot(chroma_mean_norm, chord_template)

            if match_score > best_match_score:
                best_match_score = match_score
                best_chord = chord_info

        # ã‚³ãƒ¼ãƒ‰åã‚’ç”Ÿæˆ
        chord_root_note = note_names[(root_index + best_chord['offset']) % 12]

        if best_chord['quality'] == 'maj':
            chord_name = chord_root_note
        else:
            chord_name = chord_root_note + 'm'

        # ä¿¡é ¼åº¦ã‚’0-1ã«ãƒãƒƒãƒ”ãƒ³ã‚°
        confidence = min(1.0, max(0.0, best_match_score))

        chord_progression.append(ChordInfo(
            startTime=start_time,
            endTime=end_time,
            chord=chord_name,
            rootNote=chord_root_note,
            quality=best_chord['quality'],
            confidence=confidence
        ))

    return chord_progression


def generate_fallback_chords(key_root: str, duration: float):
    """
    ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ¼ãƒ‰é€²è¡Œã‚’ç”Ÿæˆ
    """
    return [
        ChordInfo(
            startTime=0.0, endTime=4.0,
            chord=key_root, rootNote=key_root, quality='maj', confidence=0.5
        ),
    ]


def generate_scale_match(detected_key: str, scale_name: str, chord_progression: List[ChordInfo]):
    """
    ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’ç”Ÿæˆ

    1ä½: æ¨å®šã•ã‚ŒãŸã‚­ãƒ¼
    2ä½: ç›¸å¯¾èª¿ï¼ˆãƒ¡ã‚¸ãƒ£ãƒ¼â†”ãƒã‚¤ãƒŠãƒ¼ï¼‰
    """

    # æ¤œå‡ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    detected_chords = list(set([c.chord for c in chord_progression]))

    # 1ä½: æ¨å®šã‚­ãƒ¼
    first_match = ScaleMatchInfo(
        scale=scale_name,
        rootNote=detected_key,
        matchRate=0.92,
        matchingChords=detected_chords
    )

    # 2ä½: ç›¸å¯¾èª¿ã‚’è¨ˆç®—
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    root_index = note_names.index(detected_key)

    if scale_name == 'ãƒ¡ã‚¸ãƒ£ãƒ¼':
        # ç›¸å¯¾ãƒã‚¤ãƒŠãƒ¼ï¼ˆ6åº¦ä¸‹ = çŸ­6åº¦ä¸Š = 9åŠéŸ³ä¸Š = 3åŠéŸ³ä¸‹ï¼‰
        relative_index = (root_index - 3) % 12
        relative_scale = 'ãƒã‚¤ãƒŠãƒ¼'
    else:
        # ç›¸å¯¾ãƒ¡ã‚¸ãƒ£ãƒ¼ï¼ˆ3åŠéŸ³ä¸Šï¼‰
        relative_index = (root_index + 3) % 12
        relative_scale = 'ãƒ¡ã‚¸ãƒ£ãƒ¼'

    relative_key = note_names[relative_index]

    second_match = ScaleMatchInfo(
        scale=relative_scale,
        rootNote=relative_key,
        matchRate=0.85,
        matchingChords=detected_chords
    )

    # 3ä½: ãƒŸã‚¯ã‚½ãƒªãƒ‡ã‚£ã‚¢ãƒ³ï¼ˆãŠã¾ã‘ï¼‰
    third_match = ScaleMatchInfo(
        scale='ãƒŸã‚¯ã‚½ãƒªãƒ‡ã‚£ã‚¢ãƒ³',
        rootNote=detected_key,
        matchRate=0.75,
        matchingChords=detected_chords[:3] if len(detected_chords) >= 3 else detected_chords
    )

    return ScaleMatchResult(
        matchingScales=[first_match, second_match, third_match]
    )


# ============================================
# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰
# ============================================

if __name__ == "__main__":
    import uvicorn

    # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ã®èµ·å‹•ã‚³ãƒãƒ³ãƒ‰ï¼š
    # python main.py
    # ã¾ãŸã¯
    # uvicorn main:app --reload --host 0.0.0.0 --port 8000

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # ã‚³ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã«è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰
        log_level="info"
    )

"""
ã€Phase 4 ä»¥é™ã§å®Ÿè£…äºˆå®šã®é–¢æ•°ã€‘

def separate_stems(file_path: str) -> Dict[str, str]:
    \"\"\"
    stem åˆ†è§£ï¼ˆDemucs ä½¿ç”¨ï¼‰

    Args:
        file_path: éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        Dict[str, str]: stemåˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            - vocals: ãƒœãƒ¼ã‚«ãƒ«ãƒˆãƒ©ãƒƒã‚¯
            - drums: ãƒ‰ãƒ©ãƒ ãƒˆãƒ©ãƒƒã‚¯
            - bass: ãƒ™ãƒ¼ã‚¹ãƒˆãƒ©ãƒƒã‚¯
            - other: ãã®ä»–ãƒˆãƒ©ãƒƒã‚¯
    \"\"\"
    # TODO: Demucs ã‚’ä½¿ã£ãŸå®Ÿè£…
    pass


def detect_chords(y: np.ndarray, sr: int) -> List[ChordInfo]:
    \"\"\"
    ã‚³ãƒ¼ãƒ‰é€²è¡Œæ¤œå‡ºï¼ˆmadmom or librosa ä½¿ç”¨ï¼‰

    Args:
        y: éŸ³æºãƒ‡ãƒ¼ã‚¿
        sr: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ

    Returns:
        List[ChordInfo]: ã‚³ãƒ¼ãƒ‰é€²è¡Œ
    \"\"\"
    # TODO: madmom or librosa ã‚’ä½¿ã£ãŸå®Ÿè£…
    pass


def estimate_key(chroma: np.ndarray) -> Tuple[str, str]:
    \"\"\"
    ã‚­ãƒ¼æ¤œå‡º

    Args:
        chroma: ã‚¯ãƒ­ãƒã‚°ãƒ©ãƒ 

    Returns:
        Tuple[str, str]: (ã‚­ãƒ¼, ã‚¹ã‚±ãƒ¼ãƒ«)
    \"\"\"
    # TODO: ã‚­ãƒ¼æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…
    pass
"""
